{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f46574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95c8c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44ee83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer function with stemming and cleaning\n",
    "def tokenize_and_stem(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove usernames\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Stem\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5126ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 2000\n",
      "Positive reviews: 1000\n",
      "Negative reviews: 1000\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "# Extract text and labels\n",
    "texts = [' '.join(words) for words, label in documents]\n",
    "labels = [label for words, label in documents]\n",
    "\n",
    "print(f\"Total documents: {len(texts)}\")\n",
    "print(f\"Positive reviews: {labels.count('pos')}\")\n",
    "print(f\"Negative reviews: {labels.count('neg')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03955ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1600\n",
      "Test set size: 400\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254a4b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\multinomial_naive_bayes\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\multinomial_naive_bayes\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:411: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature shape: (1600, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction with TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', tokenizer=tokenize_and_stem)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF feature shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f144b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Model construction\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d7d450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7875\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.74      0.86      0.80       195\n",
      "         pos       0.84      0.72      0.78       205\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.80      0.79      0.79       400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[168  27]\n",
      " [ 58 147]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction and evaluation\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eaac464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This movie was absolutely fantastic! The acting wa...\n",
      "Predicted sentiment: pos\n",
      "\n",
      "Review: I hated this film. It was boring, the characters w...\n",
      "Predicted sentiment: neg\n",
      "\n",
      "Review: An average movie with some good moments but overal...\n",
      "Predicted sentiment: pos\n",
      "\n",
      "Review: One of the best films I've seen this year. Highly ...\n",
      "Predicted sentiment: pos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction on new queries\n",
    "new_reviews = [\n",
    "    \"This movie was absolutely fantastic! The acting was superb and the plot kept me engaged throughout.\",\n",
    "    \"I hated this film. It was boring, the characters were poorly developed, and the ending was disappointing.\",\n",
    "    \"An average movie with some good moments but overall nothing special.\",\n",
    "    \"One of the best films I've seen this year. Highly recommend it!\"\n",
    "]\n",
    "\n",
    "new_reviews_tfidf = vectorizer.transform(new_reviews)\n",
    "new_predictions = nb_classifier.predict(new_reviews_tfidf)\n",
    "\n",
    "for review, pred in zip(new_reviews, new_predictions):\n",
    "    print(f\"Review: {review[:50]}...\")\n",
    "    print(f\"Predicted sentiment: {pred}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ac7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results and Analysis ###\n",
      "\n",
      "Number of misclassified samples: 85\n",
      "\n",
      "Example misclassified samples:\n",
      "True label: pos, Predicted: neg\n",
      "Review: the makers of jurassic park & the director of speed conjure up a storm ! ( reviewed at eng wah ' s n...\n",
      "\n",
      "True label: pos, Predicted: neg\n",
      "Review: if chris farley had strapped some fake mutton - chop sideburns to each side of his head , spoken wit...\n",
      "\n",
      "True label: pos, Predicted: neg\n",
      "Review: a lot of times a three - star film will be my favorite . they ' re usually the kind of movie i can w...\n",
      "\n",
      "True label: pos, Predicted: neg\n",
      "Review: the trailers and the beginning of the move sum up this plot very easily . three filmmakers venture i...\n",
      "\n",
      "True label: pos, Predicted: neg\n",
      "Review: i have a soft spot in my heart for pure , amoral sleaze . i liked showgirls ( there , i said it ) . ...\n",
      "\n",
      "### Insights ###\n",
      "1. The Multinomial Naive Bayes classifier performed reasonably well on the movie review dataset.\n",
      "2. TF-IDF features capture the importance of words in the context of the entire corpus.\n",
      "3. The model tends to misclassify reviews that contain mixed sentiments or sarcasm.\n",
      "4. Stop words removal and limiting features to 5000 helped in reducing noise.\n",
      "5. Further improvements could include n-gram features, better preprocessing, or using more advanced models.\n"
     ]
    }
   ],
   "source": [
    "# Results and analysis\n",
    "print(\"### Results and Analysis ###\")\n",
    "\n",
    "# Example predictions (already done above)\n",
    "\n",
    "# Analysis of misclassified samples\n",
    "misclassified_indices = [i for i, (true, pred) in enumerate(zip(y_test, y_pred)) if true != pred]\n",
    "print(f\"\\nNumber of misclassified samples: {len(misclassified_indices)}\")\n",
    "\n",
    "print(\"\\nExample misclassified samples:\")\n",
    "for i in misclassified_indices[:5]:  # Show first 5\n",
    "    print(f\"True label: {y_test[i]}, Predicted: {y_pred[i]}\")\n",
    "    print(f\"Review: {X_test[i][:100]}...\")\n",
    "    print()\n",
    "\n",
    "# Insights\n",
    "print(\"### Insights ###\")\n",
    "print(\"1. The Multinomial Naive Bayes classifier performed reasonably well on the movie review dataset.\")\n",
    "print(\"2. TF-IDF features capture the importance of words in the context of the entire corpus.\")\n",
    "print(\"3. The model tends to misclassify reviews that contain mixed sentiments or sarcasm.\")\n",
    "print(\"4. Stop words removal and limiting features to 5000 helped in reducing noise.\")\n",
    "print(\"5. Further improvements could include n-gram features, better preprocessing, or using more advanced models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
